{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import re\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features From Test_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_normal_features(path_in, path_normal): \n",
    "    m = pd.read_csv(path_in)\n",
    "\n",
    "    # calculate the features\n",
    "    # question_id :\n",
    "    question_id = m['question_id']\n",
    "    question_id.to_csv(path_normal+'/qid.txt')\n",
    "\n",
    "    # vote :\n",
    "    vote = m['answer_voted']\n",
    "    vote.to_csv(path_normal+'/vote.txt')\n",
    "\n",
    "    # feature1 : length of the answer_content \n",
    "    #answer_content = m[['answer_content','user_id']]\n",
    "    answer_content = m['answer_content']\n",
    "    # f1 : length of the answer_content\n",
    "    f1 = answer_content.str.len()\n",
    "    f1.to_csv(path_normal+'/f1.txt')\n",
    "    #print answer_content\n",
    "\n",
    "\n",
    "    # feature2 : length of the user_introduction\n",
    "    user_intro = m['user_intro']\n",
    "    #print user_intro\n",
    "    f2 = user_intro.str.len()\n",
    "    f2.to_csv(path_normal+'/f2.txt')\n",
    "    #print f2\n",
    "\n",
    "\n",
    "    # feature3 : length of the question_content\n",
    "    question_content = m['question_content']\n",
    "    f3 = question_content.str.len()\n",
    "    #print f3\n",
    "    f3.to_csv(path_normal+'/f3.txt')\n",
    "\n",
    "\n",
    "    # feature4: user's experience years\n",
    "    user_exp = m['user_exp']\n",
    "    f4 = m['user_exp']\n",
    "    f4 = f4.str.extract('([0-9]*)')\n",
    "    f4.to_csv(path_normal+'/f4.txt')\n",
    "    #print f4\n",
    "\n",
    "    # feature5 : length of the user's edu\n",
    "    user_edu = m['user_edu']\n",
    "    f5 = user_edu.str.len()\n",
    "    f5.to_csv(path_normal+'/f5.txt')\n",
    "    #print f5\n",
    "\n",
    "\n",
    "    # feature6 : number of topics of user's interest\n",
    "    user_interest = m['user_interest'].str.split(' ')\n",
    "    f6 = user_interest.str.len()\n",
    "    f6.to_csv(path_normal+'/f6.txt')\n",
    "    #print f6\n",
    "\n",
    "\n",
    "    # feature7 : number of the people user followed\n",
    "    user_followed = m['user_followed'].str.split(',')\n",
    "    f7 = user_followed.str.len()\n",
    "    f7.to_csv(path_normal+'/f7.txt')\n",
    "    #print f7\n",
    "\n",
    "    # feature8 : number of the question tags\n",
    "    question_tags = m['question_tags'].str.split(' ')\n",
    "    f8 = question_tags.str.len()\n",
    "    f8.to_csv(path_normal+'/f8.txt')\n",
    "    #print f8\n",
    "\n",
    "\n",
    "    # feature9 : number of saved lives\n",
    "    saved_lives = m['user_saved']\n",
    "    f9 = saved_lives\n",
    "    f9.to_csv(path_normal+'/f9.txt')\n",
    "    #print f9\n",
    "\n",
    "\n",
    "    # feature10 : number of recieved thanks\n",
    "    recieved_thanks = m['user_thanks']\n",
    "    #recieved_thanks = str(recieved_thanks)\n",
    "    f10 = recieved_thanks.str.replace(',','')\n",
    "    f10.to_csv(path_normal+'/f10.txt')\n",
    "    #print f10\n",
    "\n",
    "\n",
    "    # feature11 : number of agrees\n",
    "    recieved_agrees = m['user_agrees']\n",
    "    f11 = recieved_agrees.str.replace(',','')\n",
    "    f11.to_csv(path_normal+'/f11.txt')\n",
    "    #print f11\n",
    "\n",
    "\n",
    "    # feature12 : nuber of helped people\n",
    "    helped = m['user_helped']\n",
    "    f12 = helped.str.replace(',','')\n",
    "    f12.to_csv(path_normal+'/f12.txt')\n",
    "    #print f12\n",
    "\n",
    "\n",
    "    # feature13 : number of doctor recommend\n",
    "    recommend = m['user_recommends']\n",
    "    f13 = recommend.str.len()\n",
    "    f13.to_csv(path_normal+'/f13.txt')\n",
    "    #print f13\n",
    "\n",
    "\n",
    "# Extracting for the TEXT FEATRUES\n",
    "def extract_text_features(path_in, path_text):\n",
    "    \n",
    "    m = pd.read_csv(path_in)\n",
    "\n",
    "    # Process with the question_content\n",
    "    qc = m['question_content']\n",
    "    qc.to_csv(path_text+'/question_content.txt', encoding='utf-8', index = False)\n",
    "\n",
    "    # Process with the answer_content\n",
    "    ac = m['answer_content']\n",
    "    ac.to_csv(path_text+'/answer_content.txt', encoding='utf-8', index = False)\n",
    "\n",
    "    # Process with the user_recommends\n",
    "    ur = m['user_recommends'].astype(str)\n",
    "    ur.to_csv(path_text+'/user_recommends.txt', encoding='utf-8', index = False)\n",
    "\n",
    "    # Process with question_tags\n",
    "    qt = m['question_tags'].astype(str)\n",
    "    qt.to_csv(path_text+'/question_tags.txt', encoding='utf-8', index = False)\n",
    "\n",
    "    # Process with user_interest\n",
    "    ut = m['user_interest'].astype(str)\n",
    "    ut.to_csv(path_text+'/user_interest.txt', encoding='utf-8', index = False)\n",
    "\n",
    "    # Proecess with user_specialty\n",
    "    us = m['user_specialty'].astype(str)\n",
    "    us.to_csv(path_text+'/user_specialty.txt', encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import izip\n",
    "\n",
    "def unique(a):\n",
    "    return list(set(a))\n",
    "\n",
    "def intersect(a,b):\n",
    "    return list(set(a)&set(b))\n",
    "\n",
    "def union(a,b):\n",
    "    return list(set(a) | set(b))\n",
    "\n",
    "def write_overlap_file(fout, overlap_list, count):\n",
    "    num_overlap = len(overlap_list) \n",
    "    fout.write(str(count)+',')\n",
    "    fout.write(' '.join(overlap_list))\n",
    "    fout.write(','+str(num_overlap)+'\\n')   \n",
    "\n",
    "    \n",
    "# Run this code for best_answer_features\n",
    "# PATH_IN = 'DIVIDE/match/best_answer_features/OVER_LAP/'\n",
    "# PATH_OUT = 'DIVIDE/match/best_answer_features/OVER_LAP/'\n",
    "# PATH_FEATURES = 'DIVIDE/match/best_answer_features/'\n",
    "\n",
    "def extract_overlap_features(PATH_TEXT, PATH_OVERLAP, PATH_NORMAL) :\n",
    "    \n",
    "    f14 = open(PATH_NORMAL + 'f14.txt', 'w')\n",
    "    f15 = open(PATH_NORMAL + 'f15.txt', 'w')\n",
    "    f16 = open(PATH_NORMAL + 'f16.txt', 'w')\n",
    "    f17 = open(PATH_NORMAL + 'f17.txt', 'w')\n",
    "    f18 = open(PATH_NORMAL + 'f18.txt', 'w')\n",
    "    f19 = open(PATH_NORMAL + 'f19.txt', 'w')\n",
    "    \n",
    "    with open(PATH_TEXT + 'answer_content.txt' , 'r') as fin_1, \\\n",
    "        open(PATH_TEXT + 'question_content.txt', 'r') as fin_2, \\\n",
    "        open(PATH_TEXT + 'question_tags.txt' , 'r') as fin_3, \\\n",
    "        open(PATH_TEXT + 'user_interest.txt' , 'r') as fin_4, \\\n",
    "        open(PATH_OVERLAP + 'answerContent_questionContent.txt', 'w') as fout_1, \\\n",
    "        open(PATH_OVERLAP + 'answerContent_questionTags.txt', 'w') as fout_2, \\\n",
    "        open(PATH_OVERLAP + 'answerContent_userInterest.txt', 'w') as fout_3, \\\n",
    "        open(PATH_OVERLAP + 'questionContent_questionTags.txt', 'w') as fout_4, \\\n",
    "        open(PATH_OVERLAP + 'questionContent_userInterest.txt', 'w') as fout_5, \\\n",
    "        open(PATH_OVERLAP + 'questionTags_userInterest.txt', 'w') as fout_7 : \n",
    "            \n",
    "            count = 0\n",
    "\n",
    "            for line1, line2, line3, line4 in izip(fin_1, fin_2, fin_3, fin_4 ):\n",
    "                word_list1 = line1.strip().split(' ')\n",
    "                word_list2 = line2.strip().split(' ')\n",
    "                word_list3 = line3.strip().split(' ')\n",
    "                word_list4 = line4.strip().split(' ')\n",
    "                \n",
    "                over_lap1 = intersect(word_list1, word_list2)\n",
    "                over_lap2 = intersect(word_list1, word_list3)\n",
    "                over_lap3 = intersect(word_list1, word_list4)\n",
    "                over_lap4 = intersect(word_list2, word_list3)\n",
    "                over_lap5 = intersect(word_list2, word_list4)\n",
    "                # over_lap6 = intersect(word_list2, word_list5)\n",
    "                over_lap7 = intersect(word_list3, word_list4)\n",
    "                # over_lap8 = intersect(word_list3, word_list5)\n",
    "                \n",
    "                # '''\n",
    "                write_overlap_file(fout_1, over_lap1, count)\n",
    "                write_overlap_file(fout_2, over_lap2, count)\n",
    "                write_overlap_file(fout_3, over_lap3, count)\n",
    "                write_overlap_file(fout_4, over_lap4, count)\n",
    "                write_overlap_file(fout_5, over_lap5, count)\n",
    "                # write_overlap_file(fout_6, over_lap6, count)\n",
    "                write_overlap_file(fout_7, over_lap7, count)\n",
    "                # write_overlap_file(fout_8, over_lap8, count)\n",
    "               \n",
    "                f14.write(str(count) + ',' + str( len(over_lap1) ) + '\\n')\n",
    "                f15.write(str(count) + ',' + str( len(over_lap2) ) + '\\n')\n",
    "                f16.write(str(count) + ',' + str( len(over_lap3) ) + '\\n')\n",
    "                f17.write(str(count) + ',' + str( len(over_lap4) ) + '\\n')\n",
    "                f18.write(str(count) + ',' + str( len(over_lap5) ) + '\\n')\n",
    "                f19.write(str(count) + ',' + str( len(over_lap7) ) + '\\n')\n",
    "                \n",
    "                count = count + 1\n",
    "    \n",
    "    f14.close()\n",
    "    f15.close()\n",
    "    f16.close()\n",
    "    f17.close()\n",
    "    f18.close()\n",
    "    f19.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lda_source(PATH_TEXT, PATH_LDA) :\n",
    "    \n",
    "    with open(PATH_TEXT + 'answer_content.txt' , 'r') as fin_1, \\\n",
    "        open(PATH_TEXT + 'question_content.txt', 'r') as fin_2, \\\n",
    "        open(PATH_TEXT + 'user_interest.txt' , 'r') as fin_3, \\\n",
    "        open(PATH_TEXT + 'question_tags.txt' , 'r') as fin_4, \\\n",
    "        open(PATH_LDA + 'TEST_LDA_SOURCE.txt', 'w') as fout :\n",
    "            for line1, line2, line3, line4 in izip(fin_1, fin_2, fin_3, fin_4) :\n",
    "                #line1 = f1.readline()\n",
    "                info1 = line1.strip()\n",
    "                # print info1\n",
    "                fout.write(info1)\n",
    "\n",
    "                #line2 = f2.readline()\n",
    "                info2 = line2.strip()\n",
    "                # print info2\n",
    "                fout.write(' '+info2)\n",
    "\n",
    "                info3 = line3.strip()\n",
    "                # print info3\n",
    "                fout.write(' '+info3)\n",
    "\n",
    "                info4 = line4.strip()\n",
    "                # print info4\n",
    "                fout.write(' '+info4 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize( PATH_NORMAL ) :\n",
    "    # feature1 : length of the answer_content \n",
    "    f1 = pd.read_csv(PATH_NORMAL + 'f1.txt', names = ['index','len_answer_content'])\n",
    "\n",
    "    # feature2 : length of the user_introduction\n",
    "    f2 = pd.read_csv(PATH_NORMAL + 'f2.txt', names = ['index','len_user_intro'])\n",
    "    m = pd.merge(f1, f2, how='outer')\n",
    "    #print m\n",
    "\n",
    "    # feature3 : length of the question_content\n",
    "    f3 = pd.read_csv(PATH_NORMAL + 'f3.txt', names = ['index', 'len_question_content'])\n",
    "    m = pd.merge(m, f3, how='outer')\n",
    "\n",
    "    # feature4: user's experience years\n",
    "    f4 = pd.read_csv(PATH_NORMAL + 'f4.txt', names = ['index','user_exp'])\n",
    "    m = pd.merge(m, f4, how='outer')\n",
    "    #print m\n",
    "\n",
    "    # feature5 : length of the user's edu\n",
    "    f5 = pd.read_csv(PATH_NORMAL + 'f5.txt', names = ['index','len_user_edu'])\n",
    "    m = pd.merge(m, f5, how='outer')\n",
    "\n",
    "    # feature6 : number of topics of user's interest\n",
    "    f6 = pd.read_csv(PATH_NORMAL + 'f6.txt', names = ['index','num_user_interst'])\n",
    "    m = pd.merge(m, f6, how='outer')\n",
    "\n",
    "    # feature7 : number of the people user followed\n",
    "    f7 = pd.read_csv(PATH_NORMAL + 'f7.txt', names = ['index','num_user_followed'])\n",
    "    m = pd.merge(m, f7, how='outer')\n",
    "\n",
    "    # feature8 : number of the question tags\n",
    "    f8 = pd.read_csv(PATH_NORMAL + 'f8.txt', names = ['index', 'num_question_tags'])\n",
    "    m = pd.merge(m, f8, how='outer')\n",
    "\n",
    "    # feature9 : number of saved lives\n",
    "    f9 = pd.read_csv(PATH_NORMAL + 'f9.txt', names = ['index','num_user_saved'])\n",
    "    m = pd.merge(m, f9, how='outer')\n",
    "\n",
    "    # feature10 : number of recieved thanks\n",
    "    f10 = pd.read_csv(PATH_NORMAL + 'f10.txt', names = ['index','num_user_thanks'])\n",
    "    m = pd.merge(m, f10, how='outer')\n",
    "\n",
    "    # feature11 : number of agrees\n",
    "    f11 = pd.read_csv(PATH_NORMAL + 'f11.txt', names = ['index','num_user_agrees'])\n",
    "    m = pd.merge(m, f11, how='outer')\n",
    "\n",
    "    # feature12 : nuber of helped people\n",
    "    f12 = pd.read_csv(PATH_NORMAL + 'f12.txt', names = ['index','num_user_helped'])\n",
    "    m = pd.merge(m, f12, how='outer')\n",
    "\n",
    "    # feature13 : number of doctor recommend\n",
    "    f13 = pd.read_csv(PATH_NORMAL + 'f13.txt', names = ['index','num_user_recommend'])\n",
    "    m = pd.merge(m, f13, how='outer')\n",
    "\n",
    "    #####################################################################\n",
    "    \n",
    "    # feature14 : answerContent & questionContent overlap \n",
    "    f14 = pd.read_csv(PATH_NORMAL + 'f14.txt', names = ['index', 'ac_qc_overlap'] )\n",
    "    m = pd.merge(m, f14, how = 'outer')\n",
    "    \n",
    "    # feature15 : answerContent & questionTags overlap\n",
    "    f15 = pd.read_csv(PATH_NORMAL + 'f15.txt', names = ['index', 'ac_qt_overlap'])\n",
    "    m = pd.merge(m, f15, how = 'outer')\n",
    "\n",
    "    # feature16 : answerContent & userInterest overlap\n",
    "    f16 = pd.read_csv(PATH_NORMAL + 'f16.txt', names = ['index', 'ac_ui_overlap'])\n",
    "    m = pd.merge(m, f16, how = 'outer')\n",
    "\n",
    "    # feature17 : questionContent & questionTags overlap\n",
    "    f17 = pd.read_csv(PATH_NORMAL + 'f17.txt', names = ['index', 'qc_qt_overlap'])\n",
    "    m = pd.merge(m, f17, how = 'outer')\n",
    "\n",
    "    # feature18 : questionContent & userInterest overlap\n",
    "    f18 = pd.read_csv(PATH_NORMAL + 'f18.txt', names = ['index', 'qc_ui_overlap'])\n",
    "    m = pd.merge(m, f18, how = 'outer')\n",
    "    \n",
    "    # feature19 : questionTags & userInterest overlap\n",
    "    f19 = pd.read_csv(PATH_NORMAL + 'f19.txt', names = ['index', 'qt_ui_overlap'])\n",
    "    m = pd.merge(m, f19, how = 'outer')\n",
    "    \n",
    "    #######################################################################\n",
    "    Index = m.ix[:,0] \n",
    "    M = m.ix[:,1:]\n",
    "\n",
    "    # M = (M - M.min()) / (M.max() - M.min())\n",
    "    M = (M - M.mean()) / M.std()\n",
    "    M['index'] = Index\n",
    "\n",
    "    # question_id :\n",
    "    # qid = pd.read_csv(PATH_IN + 'qid.txt', names = ['index', 'question_id'])\n",
    "    # M = pd.merge(M, qid, how = 'outer')\n",
    "\n",
    "    # number_of_vote\n",
    "    # vote = pd.read_csv(PATH_IN + 'vote.txt', names = ['index', 'vote'])\n",
    "    # M = pd.merge(M, vote, how = 'outer')\n",
    "\n",
    "    M = M.drop('index', axis = 1)\n",
    "    M = M.fillna(0)\n",
    "    # print M\n",
    "\n",
    "    M.to_csv(PATH_NORMAL + 'Normal_Features.txt',  index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Format S2V & Topic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_first_line(file_name) :\n",
    "    with open(file_name, 'r') as fin:\n",
    "        data = fin.read().splitlines(True)\n",
    "    with open(file_name, 'w') as fout:\n",
    "        fout.writelines(data[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# USE S2V model to generate S2V features\n",
    "def generate_s2v_features() :\n",
    "    copyfile('./LDA/TEST_LDA_SOURCE.txt', './S2V/TEST_S2V_SOURCE.txt')\n",
    "    %run /Users/gaozhipeng/ML/RANK_TEST/TEST/S2V/demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# format s2v features :\n",
    "def format_s2v_featues(PATH_LDA, PATH_S2V) :\n",
    "    s2v_list = []\n",
    "    for i in range(50) :\n",
    "        col_name = 's2v_' + str(i) \n",
    "        s2v_list.append(col_name)\n",
    "    # !!! before this , you should remove the first row of the Test_Source.txt.vec\n",
    "    remove_first_line(PATH_S2V + 'TEST_S2V_SOURCE.txt.vec')\n",
    "    total_s2v = pd.read_table(PATH_S2V + 'TEST_S2V_SOURCE.txt.vec', sep = ' ', names = s2v_list)\n",
    "    # test_s2v !!! very important : Normalization\n",
    "    total_s2v = (total_s2v - total_s2v.mean()) / total_s2v.std()\n",
    "    # total_s2v = (total_s2v - total_s2v.min()) / (total_s2v.max() - total_s2v.min())\n",
    "    # total_s2v # 11292 rows × 50 columns\n",
    "    total_s2v.to_csv(PATH_S2V + 'S2V_Features.csv', encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use Topic_Model to generate LDA Features \n",
    "def generate_topic_features():\n",
    "    %run /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/Generate_Topic_Features.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format the topic features\n",
    "def format_topic_features(PATH_LDA) :\n",
    "    \n",
    "    topic_list = []\n",
    "    for i in range(50) :\n",
    "        col_name = 'topic_' + str(i) \n",
    "        topic_list.append(col_name)\n",
    "\n",
    "    total_topic = pd.read_csv(PATH_LDA + 'Raw_Topic_Features.csv', names = topic_list, index_col=False)\n",
    "    # total_topic # 29385 rows × 50 columns\n",
    "    # test_topic !!! very important : Normalization by row\n",
    "    total_topic = total_topic.sub( total_topic.min(axis=1), axis=0 ) \n",
    "    total_topic = total_topic.div( total_topic.max(axis=1) - total_topic.min(axis=1), axis=0 )\n",
    "    # Normalize by column\n",
    "    total_topic = (total_topic - total_topic.mean()) / total_topic.std()\n",
    "    total_topic.to_csv(PATH_LDA + 'Topic_Features.csv', encoding='utf-8', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_features(PATH_NORMAL, PATH_S2V, PATH_LDA, PATH_FINAL_TEST_FEATURES, FILE) :\n",
    "    \n",
    "    Total_Normal = pd.read_csv(PATH_NORMAL + 'Normal_Features.txt')\n",
    "    Total_S2V = pd.read_csv(PATH_S2V + 'S2V_Features.csv')\n",
    "    Total_Topic = pd.read_csv(PATH_LDA + 'Topic_Features.csv')\n",
    "    \n",
    "    Total_Normal_S2V = pd.merge(Total_Normal, Total_S2V, left_index=True, right_index=True)\n",
    "    Total_Final = pd.merge(Total_Normal_S2V, Total_Topic, left_index=True, right_index=True)\n",
    "    \n",
    "    Total_Final.to_csv(PATH_FINAL_TEST_FEATURES + FILE, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LEVEL = './1000x5/'\n",
    "\n",
    "# PATH_IN = LEVEL + 'Final_Test_Set/'\n",
    "PATH_NORMAL = './NORMAL/'\n",
    "PATH_TEXT = './TEXT/'\n",
    "PATH_OVERLAP = './OVERLAP/'\n",
    "PATH_LDA = './LDA/'\n",
    "PATH_S2V = './S2V/'\n",
    "PATH_FINAL_TEST_SET = LEVEL + 'Final_Test_Set/'\n",
    "PATH_FINAL_TEST_FEATURES = LEVEL + 'Final_Test_Features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.027341 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.027341 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./1000x5/Final_Test_Set/Final_Test_00.csv\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 673 lines in 0.014252 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 673 lines in 0.014252 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x5/Final_Test_Set/Final_Test_01.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.029378 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.029378 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 681 lines in 0.014309 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 681 lines in 0.014309 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x5/Final_Test_Set/Final_Test_02.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.030221 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.030221 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 657 lines in 0.013994 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 657 lines in 0.013994 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x5/Final_Test_Set/Final_Test_03.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.036801 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.036801 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 671 lines in 0.017662 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 671 lines in 0.017662 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x5/Final_Test_Set/Final_Test_04.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.031674 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.031674 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 709 lines in 0.019636 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 709 lines in 0.019636 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x5/Final_Test_Set/Final_Test_05.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.028514 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.028514 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 712 lines in 0.015034 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 712 lines in 0.015034 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x5/Final_Test_Set/Final_Test_06.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.033046 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.033046 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 703 lines in 0.021789 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 703 lines in 0.021789 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x5/Final_Test_Set/Final_Test_07.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.03234 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.03234 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 664 lines in 0.01637 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 664 lines in 0.01637 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x5/Final_Test_Set/Final_Test_08.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.03499 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.03499 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 684 lines in 0.019874 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 684 lines in 0.019874 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x5/Final_Test_Set/Final_Test_09.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.033009 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.033009 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/gaozhipeng/ML/RANK_TEST/TEST/LDA/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 717 lines in 0.018557 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 717 lines in 0.018557 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for fname in os.listdir(PATH_FINAL_TEST_SET):\n",
    "    if fname[0] == '.':\n",
    "        continue\n",
    "    if fname.startswith('Len') : \n",
    "        continue\n",
    "    # print fname\n",
    "    # print type( fname )\n",
    "    PATH_IN = os.path.join(PATH_FINAL_TEST_SET,fname)\n",
    "    print PATH_IN\n",
    "    \n",
    "    extract_normal_features(PATH_IN, PATH_NORMAL)\n",
    "    extract_text_features(PATH_IN, PATH_TEXT)\n",
    "    extract_overlap_features(PATH_TEXT, PATH_OVERLAP, PATH_NORMAL)\n",
    "    lda_source(PATH_TEXT, PATH_LDA)\n",
    "    normalize(PATH_NORMAL)\n",
    "    generate_s2v_features()\n",
    "    format_s2v_featues(PATH_LDA, PATH_S2V)\n",
    "    generate_topic_features()\n",
    "    format_topic_features(PATH_LDA)\n",
    "    merge_features(PATH_NORMAL, PATH_S2V, PATH_LDA, PATH_FINAL_TEST_FEATURES, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Split Final_Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readlist(PATH_FINAL_TEST_SET, file_name) :\n",
    "    with open(PATH_FINAL_TEST_SET + file_name, 'r') as f :\n",
    "        line = f.readline()\n",
    "        # print line\n",
    "        len_list = line.split(' ') \n",
    "        len_list = map(int, len_list)\n",
    "        # print len_list\n",
    "    \n",
    "    return len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PATH_FINAL_TEST_SET = './1000x5/Final_Test_Set/'\n",
    "test_len = readlist(PATH_FINAL_TEST_SET, 'LEN_02.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 7)\n",
      "(1, 7, 13)\n",
      "(2, 13, 24)\n",
      "(3, 24, 31)\n",
      "(4, 31, 39)\n",
      "(5, 39, 44)\n",
      "(6, 44, 49)\n",
      "(7, 49, 55)\n",
      "(8, 55, 60)\n",
      "(9, 60, 66)\n",
      "(10, 66, 72)\n",
      "(11, 72, 80)\n",
      "(12, 80, 85)\n",
      "(13, 85, 90)\n",
      "(14, 90, 98)\n",
      "(15, 98, 103)\n",
      "(16, 103, 109)\n",
      "(17, 109, 115)\n",
      "(18, 115, 122)\n",
      "(19, 122, 130)\n",
      "(20, 130, 136)\n",
      "(21, 136, 143)\n",
      "(22, 143, 149)\n",
      "(23, 149, 155)\n",
      "(24, 155, 161)\n",
      "(25, 161, 166)\n",
      "(26, 166, 172)\n",
      "(27, 172, 181)\n",
      "(28, 181, 187)\n",
      "(29, 187, 193)\n",
      "(30, 193, 201)\n",
      "(31, 201, 206)\n",
      "(32, 206, 212)\n",
      "(33, 212, 219)\n",
      "(34, 219, 226)\n",
      "(35, 226, 232)\n",
      "(36, 232, 238)\n",
      "(37, 238, 243)\n",
      "(38, 243, 249)\n",
      "(39, 249, 254)\n",
      "(40, 254, 262)\n",
      "(41, 262, 267)\n",
      "(42, 267, 272)\n",
      "(43, 272, 279)\n",
      "(44, 279, 284)\n",
      "(45, 284, 289)\n",
      "(46, 289, 296)\n",
      "(47, 296, 301)\n",
      "(48, 301, 307)\n",
      "(49, 307, 315)\n",
      "(50, 315, 324)\n",
      "(51, 324, 330)\n",
      "(52, 330, 336)\n",
      "(53, 336, 343)\n",
      "(54, 343, 349)\n",
      "(55, 349, 355)\n",
      "(56, 355, 363)\n",
      "(57, 363, 368)\n",
      "(58, 368, 373)\n",
      "(59, 373, 378)\n",
      "(60, 378, 386)\n",
      "(61, 386, 395)\n",
      "(62, 395, 400)\n",
      "(63, 400, 406)\n",
      "(64, 406, 414)\n",
      "(65, 414, 421)\n",
      "(66, 421, 428)\n",
      "(67, 428, 435)\n",
      "(68, 435, 440)\n",
      "(69, 440, 447)\n",
      "(70, 447, 453)\n",
      "(71, 453, 459)\n",
      "(72, 459, 466)\n",
      "(73, 466, 473)\n",
      "(74, 473, 479)\n",
      "(75, 479, 488)\n",
      "(76, 488, 493)\n",
      "(77, 493, 503)\n",
      "(78, 503, 513)\n",
      "(79, 513, 520)\n",
      "(80, 520, 527)\n",
      "(81, 527, 532)\n",
      "(82, 532, 539)\n",
      "(83, 539, 545)\n",
      "(84, 545, 550)\n",
      "(85, 550, 555)\n",
      "(86, 555, 562)\n",
      "(87, 562, 570)\n",
      "(88, 570, 577)\n",
      "(89, 577, 587)\n",
      "(90, 587, 594)\n",
      "(91, 594, 600)\n",
      "(92, 600, 607)\n",
      "(93, 607, 613)\n",
      "(94, 613, 620)\n",
      "(95, 620, 628)\n",
      "(96, 628, 636)\n",
      "(97, 636, 643)\n",
      "(98, 643, 649)\n",
      "(99, 649, 657)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaozhipeng/anaconda/envs/dato-env/lib/python2.7/site-packages/IPython/kernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT THIS MAYBE CHANGE\n",
    "start = end = 0\n",
    "for i in range( len(test_len) ) :\n",
    "    end += test_len[i]\n",
    "    print (i, start, end)\n",
    "    test_i = Total_Final[start:end]\n",
    "    # test_i = (test_i - similar01_best.min()) / (similar01_best.max() - similar01_best.min())\n",
    "    # test_i.to_csv('../TOTAL_DATA_FEATURES/TEST/' + 'test_' + str(i) + '.csv', encoding='utf-8', index = False)\n",
    "    test_i.to_csv('../MODEL/SVM_Data/TEST/' + 'test_' + str(i) + '.csv', encoding='utf-8', index = False)\n",
    "    test_i.drop(test_i.columns[[2, 7, 16]], inplace=True, axis=1)\n",
    "    test_i.to_csv('../MODEL/MODEL_Data/TEST/' + 'test_' + str(i) + '.csv', encoding='utf-8', index=False, header=False)\n",
    "    start += test_len[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
